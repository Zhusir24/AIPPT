"""
AI æœåŠ¡ç±»
è´Ÿè´£è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ API ç”Ÿæˆå†…å®¹
"""

from openai import AsyncOpenAI
import asyncio
import json
import re
from typing import AsyncGenerator, Dict, Any, Optional
from sqlalchemy.orm import Session

from ..core.config import settings
from ..core.logger import get_logger, log_async_function_call
from ..models.schemas import OutlineGenerateRequest, OutlineGenerateResponse


class AIService:
    """AI æœåŠ¡ç±»"""
    
    # ç±»çº§åˆ«çš„é…ç½®å­˜å‚¨ï¼Œç”¨äºä¿æŒé…ç½®çŠ¶æ€
    _global_config = {
        "provider": None,
        "model": None,
        "api_key": None,
        "api_url": None,
        "client": None
    }
    
    def __init__(self, db: Session):
        self.db = db
        self.settings = settings  # æ·»åŠ settingså¼•ç”¨
        self.logger = get_logger(__name__)
        self.logger.debug("ğŸ¤– åˆå§‹åŒ– AI æœåŠ¡å®ä¾‹")
        
        # åŠ¨æ€æ¨¡å‹ç®¡ç†
        self.current_provider = None
        self.current_model = None
        self.client = None
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å…¨å±€é…ç½®ï¼Œå¦‚æœæœ‰åˆ™ä½¿ç”¨ï¼Œå¦åˆ™åˆå§‹åŒ–é»˜è®¤å®¢æˆ·ç«¯
        if self._global_config["client"] is not None:
            self.logger.info("ğŸ”„ ä½¿ç”¨å·²ä¿å­˜çš„APIé…ç½®")
            self.current_provider = self._global_config["provider"]
            self.current_model = self._global_config["model"]
            self.client = self._global_config["client"]
            self.logger.success(f"âœ… é…ç½®åŠ è½½æˆåŠŸ: {self.current_provider} / {self.current_model}")
        else:
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            self._initialize_default_client()
    
    def _initialize_default_client(self):
        """åˆå§‹åŒ–é»˜è®¤å®¢æˆ·ç«¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        self.logger.info("ğŸ”§ å¼€å§‹åˆå§‹åŒ–é»˜è®¤ AI å®¢æˆ·ç«¯")
        
        # åŒæ­¥æ–¹å¼é…ç½®é»˜è®¤å®¢æˆ·ç«¯
        if self.settings.DEEPSEEK_API_KEY:
            self.logger.info("ğŸ¤– ä½¿ç”¨ DeepSeek API")
            self.current_provider = "DeepSeek"
            self.current_model = self.settings.DEEPSEEK_MODEL
            self.client = AsyncOpenAI(
                api_key=self.settings.DEEPSEEK_API_KEY,
                base_url=self.settings.DEEPSEEK_BASE_URL
            )
            self.logger.success(f"âœ… DeepSeek å®¢æˆ·ç«¯é…ç½®æˆåŠŸ: {self.current_model}")
            
        elif self.settings.OPENAI_API_KEY:
            self.logger.info("ğŸ¤– ä½¿ç”¨ OpenAI API")
            self.current_provider = "OpenAI"
            self.current_model = self.settings.OPENAI_MODEL
            self.client = AsyncOpenAI(
                api_key=self.settings.OPENAI_API_KEY,
                base_url=self.settings.OPENAI_BASE_URL
            )
            self.logger.success(f"âœ… OpenAI å®¢æˆ·ç«¯é…ç½®æˆåŠŸ: {self.current_model}")
            
        elif self.settings.ANTHROPIC_API_KEY:
            self.logger.info("ğŸ¤– ä½¿ç”¨ Anthropic API")
            self.current_provider = "Anthropic"
            self.current_model = self.settings.ANTHROPIC_MODEL
            self.client = AsyncOpenAI(
                api_key=self.settings.ANTHROPIC_API_KEY,
                base_url="https://api.anthropic.com"
            )
            self.logger.success(f"âœ… Anthropic å®¢æˆ·ç«¯é…ç½®æˆåŠŸ: {self.current_model}")
            
        else:
            self.logger.error("âŒ æœªé…ç½®ä»»ä½• AI API å¯†é’¥")
            raise ValueError("è¯·é…ç½® AI API å¯†é’¥")
    
    def get_available_models(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹é…ç½®"""
        self.logger.debug("ğŸ“‹ è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨")
        
        available_models = {
            "providers": [],
            "current_provider": self.current_provider,
            "current_model": self.current_model
        }
        
        # DeepSeek æ¨¡å‹
        if self.settings.DEEPSEEK_API_KEY:
            deepseek_models = {
                "provider": "DeepSeek",
                "base_url": self.settings.DEEPSEEK_BASE_URL,
                "models": [
                    {"name": "deepseek-chat", "display_name": "DeepSeek Chat"},
                    {"name": "deepseek-coder", "display_name": "DeepSeek Coder"}
                ],
                "is_configured": True
            }
            available_models["providers"].append(deepseek_models)
            self.logger.debug(f"âœ… DeepSeek å¯ç”¨ï¼Œæ¨¡å‹æ•°: {len(deepseek_models['models'])}")
        
        # OpenAI æ¨¡å‹
        if self.settings.OPENAI_API_KEY:
            openai_models = {
                "provider": "OpenAI",
                "base_url": self.settings.OPENAI_BASE_URL,
                "models": [
                    {"name": "gpt-4o", "display_name": "GPT-4o"},
                    {"name": "gpt-4o-mini", "display_name": "GPT-4o Mini"},
                    {"name": "gpt-4-turbo", "display_name": "GPT-4 Turbo"},
                    {"name": "gpt-3.5-turbo", "display_name": "GPT-3.5 Turbo"}
                ],
                "is_configured": True
            }
            available_models["providers"].append(openai_models)
            self.logger.debug(f"âœ… OpenAI å¯ç”¨ï¼Œæ¨¡å‹æ•°: {len(openai_models['models'])}")
        
        # Anthropic æ¨¡å‹
        if self.settings.ANTHROPIC_API_KEY:
            anthropic_models = {
                "provider": "Anthropic",
                "base_url": "https://api.anthropic.com",
                "models": [
                    {"name": "claude-3-5-sonnet-20241022", "display_name": "Claude 3.5 Sonnet"},
                    {"name": "claude-3-sonnet-20240229", "display_name": "Claude 3 Sonnet"},
                    {"name": "claude-3-haiku-20240307", "display_name": "Claude 3 Haiku"}
                ],
                "is_configured": True
            }
            available_models["providers"].append(anthropic_models)
            self.logger.debug(f"âœ… Anthropic å¯ç”¨ï¼Œæ¨¡å‹æ•°: {len(anthropic_models['models'])}")
        
        self.logger.info(f"ğŸ“Š æ€»å…±æ‰¾åˆ° {len(available_models['providers'])} ä¸ªå¯ç”¨æä¾›å•†")
        return available_models
    
    async def switch_model(self, provider: str, model: str) -> Dict[str, Any]:
        """åˆ‡æ¢AIæ¨¡å‹"""
        self.logger.info(f"ğŸ”„ å¼€å§‹åˆ‡æ¢æ¨¡å‹: {provider} -> {model}")
        
        try:
            # éªŒè¯æä¾›å•†å’Œæ¨¡å‹æ˜¯å¦å¯ç”¨
            available_models = self.get_available_models()
            provider_found = False
            model_found = False
            
            for p in available_models["providers"]:
                if p["provider"] == provider:
                    provider_found = True
                    for m in p["models"]:
                        if m["name"] == model:
                            model_found = True
                            break
                    break
            
            if not provider_found:
                error_msg = f"æä¾›å•† {provider} æœªé…ç½®æˆ–ä¸å¯ç”¨"
                self.logger.error(f"âŒ {error_msg}")
                return {"success": False, "message": error_msg}
            
            if not model_found:
                error_msg = f"æ¨¡å‹ {model} åœ¨æä¾›å•† {provider} ä¸­ä¸å¯ç”¨"
                self.logger.error(f"âŒ {error_msg}")
                return {"success": False, "message": error_msg}
            
            # åˆ›å»ºæ–°çš„å®¢æˆ·ç«¯
            old_provider = self.current_provider
            old_model = self.current_model
            
            if provider == "DeepSeek":
                self.logger.debug(f"ğŸ”§ é…ç½® DeepSeek å®¢æˆ·ç«¯ï¼Œæ¨¡å‹: {model}")
                self.client = AsyncOpenAI(
                    api_key=self.settings.DEEPSEEK_API_KEY,
                    base_url=self.settings.DEEPSEEK_BASE_URL
                )
                
            elif provider == "OpenAI":
                self.logger.debug(f"ğŸ”§ é…ç½® OpenAI å®¢æˆ·ç«¯ï¼Œæ¨¡å‹: {model}")
                self.client = AsyncOpenAI(
                    api_key=self.settings.OPENAI_API_KEY,
                    base_url=self.settings.OPENAI_BASE_URL
                )
                
            elif provider == "Anthropic":
                self.logger.debug(f"ğŸ”§ é…ç½® Anthropic å®¢æˆ·ç«¯ï¼Œæ¨¡å‹: {model}")
                # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä½¿ç”¨Anthropicçš„å®¢æˆ·ç«¯ï¼Œæš‚æ—¶ç”¨OpenAIå…¼å®¹æ¥å£
                self.client = AsyncOpenAI(
                    api_key=self.settings.ANTHROPIC_API_KEY,
                    base_url="https://api.anthropic.com"
                )
            
            # æ›´æ–°å½“å‰é…ç½®
            self.current_provider = provider
            self.current_model = model
            
            # æµ‹è¯•æ–°é…ç½®
            test_result = await self._test_model_connection()
            
            if test_result["success"]:
                self.logger.success(f"ğŸ‰ æ¨¡å‹åˆ‡æ¢æˆåŠŸ: {old_provider}/{old_model} -> {provider}/{model}")
                self.logger.info(f"ğŸ”— å½“å‰ä½¿ç”¨: {provider} - {model}")
                
                return {
                    "success": True,
                    "message": f"æ¨¡å‹åˆ‡æ¢æˆåŠŸ",
                    "old_provider": old_provider,
                    "old_model": old_model,
                    "new_provider": provider,
                    "new_model": model,
                    "test_result": test_result
                }
            else:
                # åˆ‡æ¢å¤±è´¥ï¼Œå›æ»šåˆ°åŸé…ç½®
                self.logger.error(f"âŒ æ¨¡å‹è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œå›æ»šåˆ°åŸé…ç½®")
                if old_provider and old_model:
                    self.current_provider = old_provider
                    self.current_model = old_model
                    # é‡æ–°é…ç½®åŸæ¥çš„å®¢æˆ·ç«¯
                    if old_provider == "DeepSeek":
                        self.client = AsyncOpenAI(
                            api_key=self.settings.DEEPSEEK_API_KEY,
                            base_url=self.settings.DEEPSEEK_BASE_URL
                        )
                    elif old_provider == "OpenAI":
                        self.client = AsyncOpenAI(
                            api_key=self.settings.OPENAI_API_KEY,
                            base_url=self.settings.OPENAI_BASE_URL
                        )
                    elif old_provider == "Anthropic":
                        self.client = AsyncOpenAI(
                            api_key=self.settings.ANTHROPIC_API_KEY,
                            base_url="https://api.anthropic.com"
                        )
                
                return {
                    "success": False,
                    "message": f"æ¨¡å‹åˆ‡æ¢å¤±è´¥: {test_result['message']}",
                    "test_result": test_result
                }
                
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹åˆ‡æ¢å¼‚å¸¸: {str(e)}")
            self.logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            return {
                "success": False,
                "message": f"æ¨¡å‹åˆ‡æ¢å¼‚å¸¸: {str(e)}"
            }
    
    async def _test_model_connection(self) -> Dict[str, Any]:
        """æµ‹è¯•å½“å‰æ¨¡å‹è¿æ¥"""
        self.logger.debug("ğŸ§ª å¼€å§‹æµ‹è¯•æ¨¡å‹è¿æ¥")
        
        try:
            # å‘é€ç®€å•çš„æµ‹è¯•è¯·æ±‚
            response = await self.client.chat.completions.create(
                model=self.current_model,
                messages=[
                    {"role": "user", "content": "Hello, please respond with 'OK' to confirm the connection."}
                ],
                max_tokens=10,
                temperature=0
            )
            
            content = response.choices[0].message.content.strip()
            self.logger.debug(f"ğŸ” æµ‹è¯•å“åº”: {content}")
            
            if content:
                self.logger.success("âœ… æ¨¡å‹è¿æ¥æµ‹è¯•æˆåŠŸ")
                return {
                    "success": True,
                    "message": "æ¨¡å‹è¿æ¥æ­£å¸¸",
                    "test_response": content
                }
            else:
                self.logger.warning("âš ï¸ æ¨¡å‹å“åº”ä¸ºç©º")
                return {
                    "success": False,
                    "message": "æ¨¡å‹å“åº”ä¸ºç©º"
                }
                
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": f"è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}"
            }
    
    async def generate_outline(self, request: OutlineGenerateRequest) -> OutlineGenerateResponse:
        """ç”Ÿæˆå†…å®¹å¤§çº²"""
        self.logger.info("ğŸ“ å¼€å§‹ç”Ÿæˆå†…å®¹å¤§çº²")
        self.logger.debug(f"ğŸ“‹ è¯·æ±‚å‚æ•°: topic={request.topic}, language={request.language}, length={request.outline_length}")
        
        try:
            # æ„å»ºæç¤ºè¯
            self.logger.debug("ğŸ”¨ æ„å»ºå¤§çº²ç”Ÿæˆæç¤ºè¯")
            prompt = self._build_outline_prompt(request)
            self.logger.debug(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            
            # è·å–æ¨¡å‹åç§°
            model_name = self._get_model_name()
            self.logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_name}")
            
            # è°ƒç”¨ AI API
            self.logger.info("âš¡ å¼€å§‹è°ƒç”¨ AI API ç”Ÿæˆå¤§çº²")
            response = await self.client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ PPT å†…å®¹ç­–åˆ’å¸ˆï¼Œæ“…é•¿åˆ›å»ºç»“æ„æ¸…æ™°ã€å†…å®¹ä¸°å¯Œçš„æ¼”ç¤ºæ–‡ç¨¿å¤§çº²ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            self.logger.success("âœ… AI API è°ƒç”¨æˆåŠŸ")
            
            # å¤„ç†å“åº”
            content = response.choices[0].message.content
            self.logger.info(f"ğŸ“Š ç”Ÿæˆå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            self.logger.debug(f"ğŸ“„ ç”Ÿæˆå†…å®¹é¢„è§ˆ: {content[:200]}...")
            
            # è§£æå¤§çº²æ ‘ç»“æ„
            self.logger.debug("ğŸŒ² è§£æå¤§çº²æ ‘ç»“æ„")
            outline_tree = self._parse_outline_to_tree(content)
            self.logger.info(f"ğŸ”¢ è§£æå‡º {len(outline_tree)} ä¸ªä¸»è¦ç« èŠ‚")
            
            self.logger.success("ğŸ‰ å¤§çº²ç”Ÿæˆå®Œæˆ")
            return OutlineGenerateResponse(
                outline_markdown=content,
                outline_tree=outline_tree,
                status="success"
            )
            
        except Exception as e:
            self.logger.error(f"âŒ ç”Ÿæˆå¤§çº²å¤±è´¥: {str(e)}")
            self.logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            return OutlineGenerateResponse(
                outline_markdown="",
                outline_tree=[],
                status="error",
                error_message=str(e)
            )
    
    async def generate_outline_stream(self, request: OutlineGenerateRequest) -> AsyncGenerator[str, None]:
        """æµå¼ç”Ÿæˆå†…å®¹å¤§çº²"""
        self.logger.info("ğŸŒŠ å¼€å§‹æµå¼ç”Ÿæˆå†…å®¹å¤§çº²")
        self.logger.debug(f"ğŸ“‹ è¯·æ±‚å‚æ•°: topic={request.topic}, language={request.language}, length={request.outline_length}")
        
        try:
            # æ„å»ºæç¤ºè¯
            self.logger.debug("ğŸ”¨ æ„å»ºæµå¼å¤§çº²ç”Ÿæˆæç¤ºè¯")
            prompt = self._build_outline_prompt(request)
            self.logger.debug(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            
            # è·å–æ¨¡å‹åç§°
            model_name = self._get_model_name()
            self.logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_name}")
            
            # è°ƒç”¨æµå¼ AI API
            self.logger.info("âš¡ å¼€å§‹è°ƒç”¨æµå¼ AI API")
            stream = await self.client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ PPT å†…å®¹ç­–åˆ’å¸ˆï¼Œæ“…é•¿åˆ›å»ºç»“æ„æ¸…æ™°ã€å†…å®¹ä¸°å¯Œçš„æ¼”ç¤ºæ–‡ç¨¿å¤§çº²ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000,
                stream=True
            )
            
            self.logger.success("âœ… æµå¼ API è°ƒç”¨æˆåŠŸï¼Œå¼€å§‹æ¥æ”¶æ•°æ®æµ")
            
            chunk_count = 0
            total_content = ""
            
            async for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    chunk_count += 1
                    content_chunk = chunk.choices[0].delta.content
                    total_content += content_chunk
                    
                    if chunk_count % 10 == 0:  # æ¯10ä¸ªchunkè®°å½•ä¸€æ¬¡
                        self.logger.debug(f"ğŸ“¦ å·²æ¥æ”¶ {chunk_count} ä¸ªæ•°æ®å—ï¼Œå½“å‰å†…å®¹é•¿åº¦: {len(total_content)}")
                    
                    yield content_chunk
            
            self.logger.success(f"ğŸ‰ æµå¼ç”Ÿæˆå®Œæˆï¼Œå…±æ¥æ”¶ {chunk_count} ä¸ªæ•°æ®å—ï¼Œæ€»é•¿åº¦: {len(total_content)} å­—ç¬¦")
                    
        except Exception as e:
            self.logger.error(f"âŒ æµå¼ç”Ÿæˆå¤§çº²å¤±è´¥: {str(e)}")
            self.logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            yield f"é”™è¯¯: {str(e)}"
    
    async def generate_content(self, outline: str, template_info: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¹æ®å¤§çº²ç”Ÿæˆè¯¦ç»†å†…å®¹"""
        self.logger.info("ğŸ“„ å¼€å§‹ç”Ÿæˆè¯¦ç»†å†…å®¹")
        self.logger.debug(f"ğŸ“ å¤§çº²é•¿åº¦: {len(outline)} å­—ç¬¦")
        self.logger.debug(f"ğŸ¨ æ¨¡æ¿ä¿¡æ¯: {template_info}")
        
        try:
            # æ„å»ºå†…å®¹ç”Ÿæˆæç¤ºè¯
            self.logger.debug("ğŸ”¨ æ„å»ºå†…å®¹ç”Ÿæˆæç¤ºè¯")
            prompt = self._build_content_prompt(outline, template_info)
            self.logger.debug(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            
            # è·å–æ¨¡å‹åç§°
            model_name = self._get_model_name()
            self.logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_name}")
            
            # è°ƒç”¨ AI API ç”Ÿæˆå†…å®¹
            self.logger.info("âš¡ å¼€å§‹è°ƒç”¨ AI API ç”Ÿæˆè¯¦ç»†å†…å®¹")
            response = await self.client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ›ä½œå¸ˆï¼Œèƒ½å¤Ÿæ ¹æ®å¤§çº²åˆ›å»ºè¯¦ç»†çš„æ¼”ç¤ºæ–‡ç¨¿å†…å®¹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=3000
            )
            
            self.logger.success("âœ… å†…å®¹ç”Ÿæˆ API è°ƒç”¨æˆåŠŸ")
            
            # å¤„ç†ç”Ÿæˆçš„å†…å®¹
            content = response.choices[0].message.content
            self.logger.info(f"ğŸ“Š ç”Ÿæˆå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            self.logger.debug(f"ğŸ“„ ç”Ÿæˆå†…å®¹é¢„è§ˆ: {content[:300]}...")
            
            # è§£æå†…å®¹ä¸ºå¹»ç¯ç‰‡ç»“æ„
            self.logger.debug("ğŸ¯ è§£æå†…å®¹ä¸ºå¹»ç¯ç‰‡ç»“æ„")
            parsed_slides = self._parse_content_to_slides(content)
            self.logger.info(f"ğŸ”¢ è§£æå‡º {len(parsed_slides.get('slides', []))} å¼ å¹»ç¯ç‰‡")
            
            self.logger.success("ğŸ‰ è¯¦ç»†å†…å®¹ç”Ÿæˆå®Œæˆ")
            return parsed_slides
            
        except Exception as e:
            self.logger.error(f"âŒ ç”Ÿæˆè¯¦ç»†å†…å®¹å¤±è´¥: {str(e)}")
            self.logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            return {"error": str(e), "slides": []}
    
    async def expand_content(self, section_title: str, current_content: str) -> str:
        """æ‰©å±•æŒ‡å®šç« èŠ‚çš„å†…å®¹"""
        self.logger.info("ğŸ” å¼€å§‹æ‰©å±•ç« èŠ‚å†…å®¹")
        self.logger.info(f"ğŸ“ ç« èŠ‚æ ‡é¢˜: {section_title}")
        self.logger.debug(f"ğŸ“„ å½“å‰å†…å®¹é•¿åº¦: {len(current_content)} å­—ç¬¦")
        self.logger.debug(f"ğŸ“„ å½“å‰å†…å®¹é¢„è§ˆ: {current_content[:200]}...")
        
        try:
            # æ„å»ºæ‰©å±•æç¤ºè¯
            self.logger.debug("ğŸ”¨ æ„å»ºå†…å®¹æ‰©å±•æç¤ºè¯")
            prompt = f"""
è¯·æ‰©å±•ä»¥ä¸‹ç« èŠ‚çš„å†…å®¹ï¼Œä½¿å…¶æ›´åŠ è¯¦ç»†å’Œä¸°å¯Œï¼š

ç« èŠ‚æ ‡é¢˜ï¼š{section_title}
å½“å‰å†…å®¹ï¼š{current_content}

è¦æ±‚ï¼š
1. ä¿æŒåŸæœ‰å†…å®¹çš„æ ¸å¿ƒè§‚ç‚¹
2. å¢åŠ æ›´å¤šç»†èŠ‚å’Œä¾‹å­
3. ç¡®ä¿å†…å®¹é€»è¾‘æ¸…æ™°
4. å­—æ•°å¢åŠ 50-100%
"""
            self.logger.debug(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            
            # è·å–æ¨¡å‹åç§°
            model_name = self._get_model_name()
            self.logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_name}")
            
            # è°ƒç”¨ AI API æ‰©å±•å†…å®¹
            self.logger.info("âš¡ å¼€å§‹è°ƒç”¨ AI API æ‰©å±•å†…å®¹")
            response = await self.client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹æ‰©å±•å¸ˆï¼Œæ“…é•¿ä¸°å¯Œå’Œå®Œå–„ç°æœ‰å†…å®¹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.6,
                max_tokens=1500
            )
            
            self.logger.success("âœ… å†…å®¹æ‰©å±• API è°ƒç”¨æˆåŠŸ")
            
            # å¤„ç†æ‰©å±•åçš„å†…å®¹
            expanded_content = response.choices[0].message.content
            self.logger.info(f"ğŸ“Š æ‰©å±•åå†…å®¹é•¿åº¦: {len(expanded_content)} å­—ç¬¦")
            self.logger.info(f"ğŸ“ˆ å†…å®¹å¢é•¿: {len(expanded_content) - len(current_content)} å­—ç¬¦")
            self.logger.debug(f"ğŸ“„ æ‰©å±•åå†…å®¹é¢„è§ˆ: {expanded_content[:300]}...")
            
            self.logger.success("ğŸ‰ å†…å®¹æ‰©å±•å®Œæˆ")
            return expanded_content
            
        except Exception as e:
            self.logger.error(f"âŒ æ‰©å±•å†…å®¹å¤±è´¥: {str(e)}")
            self.logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            return f"æ‰©å±•å¤±è´¥: {str(e)}"
    
    def _get_model_name(self) -> str:
        """è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°"""
        return self.current_model if self.current_model else "deepseek-chat"
    
    def get_current_provider(self) -> str:
        """è·å–å½“å‰AIæä¾›å•†"""
        return self.current_provider if self.current_provider else "æœªé…ç½®"
    
    def _build_outline_prompt(self, request: OutlineGenerateRequest) -> str:
        """æ„å»ºå¤§çº²ç”Ÿæˆæç¤ºè¯"""
        length_map = {
            "ç®€çŸ­": "3-5ä¸ªä¸»è¦ç« èŠ‚",
            "ä¸­ç­‰": "5-8ä¸ªä¸»è¦ç« èŠ‚", 
            "è¯¦ç»†": "8-12ä¸ªä¸»è¦ç« èŠ‚"
        }
        
        sections_requirement = length_map.get(request.outline_length, "5-8ä¸ªä¸»è¦ç« èŠ‚")
        
        prompt = f"""
è¯·ä¸ºä»¥ä¸‹ä¸»é¢˜åˆ›å»ºä¸€ä¸ªè¯¦ç»†çš„PPTæ¼”ç¤ºå¤§çº²ï¼š

ä¸»é¢˜ï¼š{request.topic}
ç›®æ ‡å—ä¼—ï¼š{request.target_audience or 'ä¸€èˆ¬å—ä¼—'}
æ¼”ç¤ºæ—¶é•¿ï¼š{request.presentation_duration or '15-20åˆ†é’Ÿ'}
å¤§çº²è¯¦ç»†ç¨‹åº¦ï¼š{request.outline_length}ï¼ˆ{sections_requirement}ï¼‰
æ¼”ç¤ºè¯­è¨€ï¼š{request.language}

é¢å¤–è¦æ±‚ï¼š
{request.additional_requirements or 'æ— ç‰¹æ®Šè¦æ±‚'}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºå¤§çº²ï¼š

# æ¼”ç¤ºä¸»é¢˜

## 1. å¼€åœºå¼•å…¥
- é—®å€™å’Œè‡ªæˆ‘ä»‹ç»
- ä¸»é¢˜æ¦‚è¿°
- æ¼”ç¤ºå¤§çº²é¢„è§ˆ

## 2. [ä¸»è¦ç« èŠ‚æ ‡é¢˜]
- [ä¸»è¦è§‚ç‚¹1]
  - [æ”¯æ’‘ç»†èŠ‚]
  - [ä¾‹å­æˆ–æ•°æ®]
- [ä¸»è¦è§‚ç‚¹2]
  - [æ”¯æ’‘ç»†èŠ‚]

## 3. [ä¸»è¦ç« èŠ‚æ ‡é¢˜]
...

## ç»“æŸè¯­
- æ€»ç»“è¦ç‚¹
- è¡ŒåŠ¨å‘¼å
- æ„Ÿè°¢å’Œé—®ç­”

è¦æ±‚ï¼š
1. å¤§çº²ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘æ€§å¼º
2. æ¯ä¸ªç« èŠ‚éƒ½æœ‰å…·ä½“çš„å†…å®¹è¦ç‚¹
3. é€‚åˆ{request.presentation_duration or '15-20åˆ†é’Ÿ'}çš„æ¼”ç¤ºæ—¶é•¿
4. å†…å®¹å®ç”¨ä¸”æœ‰ä»·å€¼
5. ä½¿ç”¨{request.language}è¯­è¨€"""

        return prompt
    
    def _build_content_prompt(self, outline: str, template_info: Dict[str, Any]) -> str:
        """æ„å»ºå†…å®¹ç”Ÿæˆæç¤ºè¯"""
        template_name = template_info.get('name', 'é»˜è®¤æ¨¡æ¿')
        template_style = template_info.get('description', 'ç®€æ´ä¸“ä¸šé£æ ¼')
        
        prompt = f"""
åŸºäºä»¥ä¸‹å¤§çº²ï¼Œä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆè¯¦ç»†çš„æ¼”ç¤ºå†…å®¹ï¼š

å¤§çº²ï¼š
{outline}

æ¨¡æ¿ä¿¡æ¯ï¼š
- æ¨¡æ¿åç§°ï¼š{template_name}
- é£æ ¼ç‰¹ç‚¹ï¼š{template_style}

è¯·ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆï¼š
1. æ ‡é¢˜é¡µå†…å®¹
2. è¯¦ç»†å†…å®¹é¡µ
3. å…³é”®è¦ç‚¹æ€»ç»“

è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
  "slides": [
    {{
      "type": "title",
      "title": "ç« èŠ‚æ ‡é¢˜",
      "subtitle": "å‰¯æ ‡é¢˜æˆ–æ¦‚è¿°",
      "section": 1
    }},
    {{
      "type": "content", 
      "title": "å†…å®¹æ ‡é¢˜",
      "content": [
        "è¦ç‚¹1ï¼šè¯¦ç»†è¯´æ˜",
        "è¦ç‚¹2ï¼šè¯¦ç»†è¯´æ˜"
      ],
      "section": 1
    }}
  ]
}}

è¦æ±‚ï¼š
1. å†…å®¹è¯¦å®å…·ä½“ï¼Œé¿å…ç©ºæ³›è¡¨è¿°
2. é€‚åˆæ¼”ç¤ºæ–‡ç¨¿çš„è¡¨è¾¾æ–¹å¼
3. æ¯é¡µå†…å®¹é‡é€‚ä¸­ï¼Œä¾¿äºé˜…è¯»
4. ä¿æŒé£æ ¼ä¸€è‡´æ€§"""

        return prompt
    
    def _parse_outline_to_tree(self, markdown_content: str) -> list:
        """å°† Markdown å¤§çº²è§£æä¸ºæ ‘å½¢ç»“æ„"""
        lines = markdown_content.strip().split('\n')
        tree = []
        current_section = None
        current_subsection = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ä¸»æ ‡é¢˜ (# æˆ– ##)
            if line.startswith('# ') or line.startswith('## '):
                if line.startswith('# '):
                    title = line[2:].strip()
                else:
                    title = line[3:].strip()
                    
                current_section = {
                    "title": title,
                    "level": 1,
                    "children": []
                }
                tree.append(current_section)
                current_subsection = None
                
            # å­æ ‡é¢˜ (### æˆ–æ›´å¤š)
            elif line.startswith('###'):
                if current_section:
                    subtitle = line[3:].strip()
                    current_subsection = {
                        "title": subtitle,
                        "level": 2,
                        "children": []
                    }
                    current_section["children"].append(current_subsection)
                    
            # åˆ—è¡¨é¡¹
            elif line.startswith('- '):
                content = line[2:].strip()
                item = {
                    "title": content,
                    "level": 3,
                    "children": []
                }
                
                if current_subsection:
                    current_subsection["children"].append(item)
                elif current_section:
                    current_section["children"].append(item)
        
        return tree
    
    def _parse_content_to_slides(self, content: str) -> Dict[str, Any]:
        """è§£æç”Ÿæˆçš„å†…å®¹ä¸ºå¹»ç¯ç‰‡æ ¼å¼"""
        self.logger.debug(f"ğŸ” å¼€å§‹è§£æå†…å®¹ï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
        self.logger.debug(f"ğŸ“„ å†…å®¹å‰500å­—ç¬¦: {content[:500]}...")
        
        try:
            # å°è¯•è§£æ JSON æ ¼å¼çš„å†…å®¹
            parsed_json = json.loads(content)
            self.logger.debug("âœ… å†…å®¹ä¸ºJSONæ ¼å¼ï¼Œç›´æ¥è¿”å›")
            return parsed_json
        except json.JSONDecodeError:
            self.logger.debug("âš ï¸ å†…å®¹éJSONæ ¼å¼ï¼Œè¿›è¡Œæ–‡æœ¬è§£æ")
            # å¦‚æœä¸æ˜¯ JSON æ ¼å¼ï¼Œåˆ™è¿›è¡Œç®€å•çš„æ–‡æœ¬è§£æ
            lines = content.strip().split('\n')
            slides = []
            current_slide = None
            
            self.logger.debug(f"ğŸ“ æ€»è¡Œæ•°: {len(lines)}")
            
            for i, line in enumerate(lines):
                line = line.strip()
                if not line:
                    continue
                    
                if line.startswith('#'):
                    if current_slide:
                        slides.append(current_slide)
                        self.logger.debug(f"ğŸ“„ å®Œæˆå¹»ç¯ç‰‡: {current_slide['title']}")
                    
                    title = line.lstrip('#').strip()
                    current_slide = {
                        "type": "content",
                        "title": title,
                        "content": [],
                        "section": len(slides) + 1
                    }
                    self.logger.debug(f"ğŸ†• æ–°å¹»ç¯ç‰‡: {title}")
                elif line.startswith('-') and current_slide:
                    current_slide["content"].append(line[1:].strip())
                    self.logger.debug(f"â• æ·»åŠ å†…å®¹: {line[1:].strip()}")
            
            if current_slide:
                slides.append(current_slide)
                self.logger.debug(f"ğŸ“„ å®Œæˆæœ€åå¹»ç¯ç‰‡: {current_slide['title']}")
            
            self.logger.debug(f"ğŸ¯ è§£æå®Œæˆï¼Œå…± {len(slides)} å¼ å¹»ç¯ç‰‡")
            return {"slides": slides}
    
    def _apply_custom_config(self, api_key: str, api_url: str, model_name: str):
        """åº”ç”¨è‡ªå®šä¹‰APIé…ç½®"""
        from openai import AsyncOpenAI
        
        self.logger.info(f"ğŸ”§ åº”ç”¨è‡ªå®šä¹‰é…ç½®: {api_url} / {model_name}")
        
        self.current_provider = "Custom"
        self.current_model = model_name
        self.client = AsyncOpenAI(
            api_key=api_key,
            base_url=api_url
        )
        
        # æ›´æ–°å…¨å±€é…ç½®
        self._global_config.update({
            "provider": "Custom",
            "model": model_name,
            "api_key": api_key,
            "api_url": api_url,
            "client": self.client
        })
        
        self.logger.success(f"âœ… è‡ªå®šä¹‰å®¢æˆ·ç«¯é…ç½®æˆåŠŸ: {model_name}")
        
    def _apply_openai_config(self, api_key: str):
        """åº”ç”¨OpenAIé…ç½®"""
        from openai import AsyncOpenAI
        
        self.logger.info("ğŸ”§ åº”ç”¨OpenAIé…ç½®")
        
        self.current_provider = "OpenAI"
        self.current_model = "gpt-3.5-turbo"
        self.client = AsyncOpenAI(
            api_key=api_key,
            base_url="https://api.openai.com/v1"
        )
        
        # æ›´æ–°å…¨å±€é…ç½®
        self._global_config.update({
            "provider": "OpenAI",
            "model": "gpt-3.5-turbo",
            "api_key": api_key,
            "api_url": "https://api.openai.com/v1",
            "client": self.client
        })
        
        self.logger.success(f"âœ… OpenAIå®¢æˆ·ç«¯é…ç½®æˆåŠŸ: {self.current_model}")
        
    def _apply_deepseek_config(self, api_key: str):
        """åº”ç”¨DeepSeeké…ç½®"""
        from openai import AsyncOpenAI
        
        self.logger.info("ğŸ”§ åº”ç”¨DeepSeeké…ç½®")
        
        self.current_provider = "DeepSeek"
        self.current_model = "deepseek-chat"
        self.client = AsyncOpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com/v1"
        )
        
        # æ›´æ–°å…¨å±€é…ç½®
        self._global_config.update({
            "provider": "DeepSeek",
            "model": "deepseek-chat",
            "api_key": api_key,
            "api_url": "https://api.deepseek.com/v1",
            "client": self.client
        })
        
        self.logger.success(f"âœ… DeepSeekå®¢æˆ·ç«¯é…ç½®æˆåŠŸ: {self.current_model}") 