"""
AI æœåŠ¡ç±»
è´Ÿè´£è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ API ç”Ÿæˆå†…å®¹
"""

from openai import AsyncOpenAI
import asyncio
import json
import re
from typing import AsyncGenerator, Dict, Any, Optional
from sqlalchemy.orm import Session

from ..core.config import settings
from ..core.logger import get_logger, log_async_function_call
from ..models.schemas import OutlineGenerateRequest, OutlineGenerateResponse


class AIService:
    """AI æœåŠ¡ç±»"""
    
    def __init__(self, db: Session):
        self.db = db
        self.settings = settings  # æ·»åŠ settingså¼•ç”¨
        self.logger = get_logger(__name__)
        self.logger.debug("ğŸ¤– åˆå§‹åŒ– AI æœåŠ¡å®ä¾‹")
        self.client = self.setup_openai_client()
    
    def setup_openai_client(self) -> AsyncOpenAI:
        """é…ç½® OpenAI å®¢æˆ·ç«¯"""
        self.logger.info("ğŸ”§ å¼€å§‹é…ç½® AI å®¢æˆ·ç«¯")
        
        # ä¼˜å…ˆä½¿ç”¨ DeepSeek API
        if self.settings.DEEPSEEK_API_KEY:
            self.logger.info("ğŸ¤– ä½¿ç”¨ DeepSeek API")
            self.logger.debug(f"ğŸ”— DeepSeek Base URL: {self.settings.DEEPSEEK_BASE_URL}")
            client = AsyncOpenAI(
                api_key=self.settings.DEEPSEEK_API_KEY,
                base_url=self.settings.DEEPSEEK_BASE_URL
            )
            self.logger.success("âœ… DeepSeek å®¢æˆ·ç«¯é…ç½®æˆåŠŸ")
            return client
        elif self.settings.OPENAI_API_KEY:
            self.logger.info("ğŸ¤– ä½¿ç”¨ OpenAI API")
            self.logger.debug(f"ğŸ”— OpenAI Base URL: {self.settings.OPENAI_BASE_URL}")
            client = AsyncOpenAI(
                api_key=self.settings.OPENAI_API_KEY,
                base_url=self.settings.OPENAI_BASE_URL
            )
            self.logger.success("âœ… OpenAI å®¢æˆ·ç«¯é…ç½®æˆåŠŸ")
            return client
        else:
            self.logger.error("âŒ æœªé…ç½®ä»»ä½• AI API å¯†é’¥")
            raise ValueError("è¯·é…ç½® AI API å¯†é’¥")
    
    async def generate_outline(self, request: OutlineGenerateRequest) -> OutlineGenerateResponse:
        """ç”Ÿæˆå†…å®¹å¤§çº²"""
        self.logger.info("ğŸ“ å¼€å§‹ç”Ÿæˆå†…å®¹å¤§çº²")
        self.logger.debug(f"ğŸ“‹ è¯·æ±‚å‚æ•°: topic={request.topic}, language={request.language}, length={request.outline_length}")
        
        try:
            # æ„å»ºæç¤ºè¯
            self.logger.debug("ğŸ”¨ æ„å»ºå¤§çº²ç”Ÿæˆæç¤ºè¯")
            prompt = self._build_outline_prompt(request)
            self.logger.debug(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            
            # è·å–æ¨¡å‹åç§°
            model_name = self._get_model_name()
            self.logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_name}")
            
            # è°ƒç”¨ AI API
            self.logger.info("âš¡ å¼€å§‹è°ƒç”¨ AI API ç”Ÿæˆå¤§çº²")
            response = await self.client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ PPT å†…å®¹ç­–åˆ’å¸ˆï¼Œæ“…é•¿åˆ›å»ºç»“æ„æ¸…æ™°ã€å†…å®¹ä¸°å¯Œçš„æ¼”ç¤ºæ–‡ç¨¿å¤§çº²ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            self.logger.success("âœ… AI API è°ƒç”¨æˆåŠŸ")
            
            # å¤„ç†å“åº”
            content = response.choices[0].message.content
            self.logger.info(f"ğŸ“Š ç”Ÿæˆå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            self.logger.debug(f"ğŸ“„ ç”Ÿæˆå†…å®¹é¢„è§ˆ: {content[:200]}...")
            
            # è§£æå¤§çº²æ ‘ç»“æ„
            self.logger.debug("ğŸŒ² è§£æå¤§çº²æ ‘ç»“æ„")
            outline_tree = self._parse_outline_to_tree(content)
            self.logger.info(f"ğŸ”¢ è§£æå‡º {len(outline_tree)} ä¸ªä¸»è¦ç« èŠ‚")
            
            self.logger.success("ğŸ‰ å¤§çº²ç”Ÿæˆå®Œæˆ")
            return OutlineGenerateResponse(
                outline_markdown=content,
                outline_tree=outline_tree,
                status="success"
            )
            
        except Exception as e:
            self.logger.error(f"âŒ ç”Ÿæˆå¤§çº²å¤±è´¥: {str(e)}")
            self.logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            return OutlineGenerateResponse(
                outline_markdown="",
                outline_tree=[],
                status="error",
                error_message=str(e)
            )
    
    async def generate_outline_stream(self, request: OutlineGenerateRequest) -> AsyncGenerator[str, None]:
        """æµå¼ç”Ÿæˆå†…å®¹å¤§çº²"""
        self.logger.info("ğŸŒŠ å¼€å§‹æµå¼ç”Ÿæˆå†…å®¹å¤§çº²")
        self.logger.debug(f"ğŸ“‹ è¯·æ±‚å‚æ•°: topic={request.topic}, language={request.language}, length={request.outline_length}")
        
        try:
            # æ„å»ºæç¤ºè¯
            self.logger.debug("ğŸ”¨ æ„å»ºæµå¼å¤§çº²ç”Ÿæˆæç¤ºè¯")
            prompt = self._build_outline_prompt(request)
            self.logger.debug(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            
            # è·å–æ¨¡å‹åç§°
            model_name = self._get_model_name()
            self.logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_name}")
            
            # è°ƒç”¨æµå¼ AI API
            self.logger.info("âš¡ å¼€å§‹è°ƒç”¨æµå¼ AI API")
            stream = await self.client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ PPT å†…å®¹ç­–åˆ’å¸ˆï¼Œæ“…é•¿åˆ›å»ºç»“æ„æ¸…æ™°ã€å†…å®¹ä¸°å¯Œçš„æ¼”ç¤ºæ–‡ç¨¿å¤§çº²ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000,
                stream=True
            )
            
            self.logger.success("âœ… æµå¼ API è°ƒç”¨æˆåŠŸï¼Œå¼€å§‹æ¥æ”¶æ•°æ®æµ")
            
            chunk_count = 0
            total_content = ""
            
            async for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    chunk_count += 1
                    content_chunk = chunk.choices[0].delta.content
                    total_content += content_chunk
                    
                    if chunk_count % 10 == 0:  # æ¯10ä¸ªchunkè®°å½•ä¸€æ¬¡
                        self.logger.debug(f"ğŸ“¦ å·²æ¥æ”¶ {chunk_count} ä¸ªæ•°æ®å—ï¼Œå½“å‰å†…å®¹é•¿åº¦: {len(total_content)}")
                    
                    yield content_chunk
            
            self.logger.success(f"ğŸ‰ æµå¼ç”Ÿæˆå®Œæˆï¼Œå…±æ¥æ”¶ {chunk_count} ä¸ªæ•°æ®å—ï¼Œæ€»é•¿åº¦: {len(total_content)} å­—ç¬¦")
                    
        except Exception as e:
            self.logger.error(f"âŒ æµå¼ç”Ÿæˆå¤§çº²å¤±è´¥: {str(e)}")
            self.logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            yield f"é”™è¯¯: {str(e)}"
    
    async def generate_content(self, outline: str, template_info: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¹æ®å¤§çº²ç”Ÿæˆè¯¦ç»†å†…å®¹"""
        self.logger.info("ğŸ“„ å¼€å§‹ç”Ÿæˆè¯¦ç»†å†…å®¹")
        self.logger.debug(f"ğŸ“ å¤§çº²é•¿åº¦: {len(outline)} å­—ç¬¦")
        self.logger.debug(f"ğŸ¨ æ¨¡æ¿ä¿¡æ¯: {template_info}")
        
        try:
            # æ„å»ºå†…å®¹ç”Ÿæˆæç¤ºè¯
            self.logger.debug("ğŸ”¨ æ„å»ºå†…å®¹ç”Ÿæˆæç¤ºè¯")
            prompt = self._build_content_prompt(outline, template_info)
            self.logger.debug(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            
            # è·å–æ¨¡å‹åç§°
            model_name = self._get_model_name()
            self.logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_name}")
            
            # è°ƒç”¨ AI API ç”Ÿæˆå†…å®¹
            self.logger.info("âš¡ å¼€å§‹è°ƒç”¨ AI API ç”Ÿæˆè¯¦ç»†å†…å®¹")
            response = await self.client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ›ä½œå¸ˆï¼Œèƒ½å¤Ÿæ ¹æ®å¤§çº²åˆ›å»ºè¯¦ç»†çš„æ¼”ç¤ºæ–‡ç¨¿å†…å®¹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=3000
            )
            
            self.logger.success("âœ… å†…å®¹ç”Ÿæˆ API è°ƒç”¨æˆåŠŸ")
            
            # å¤„ç†ç”Ÿæˆçš„å†…å®¹
            content = response.choices[0].message.content
            self.logger.info(f"ğŸ“Š ç”Ÿæˆå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            self.logger.debug(f"ğŸ“„ ç”Ÿæˆå†…å®¹é¢„è§ˆ: {content[:300]}...")
            
            # è§£æå†…å®¹ä¸ºå¹»ç¯ç‰‡ç»“æ„
            self.logger.debug("ğŸ¯ è§£æå†…å®¹ä¸ºå¹»ç¯ç‰‡ç»“æ„")
            parsed_slides = self._parse_content_to_slides(content)
            self.logger.info(f"ğŸ”¢ è§£æå‡º {len(parsed_slides.get('slides', []))} å¼ å¹»ç¯ç‰‡")
            
            self.logger.success("ğŸ‰ è¯¦ç»†å†…å®¹ç”Ÿæˆå®Œæˆ")
            return parsed_slides
            
        except Exception as e:
            self.logger.error(f"âŒ ç”Ÿæˆè¯¦ç»†å†…å®¹å¤±è´¥: {str(e)}")
            self.logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            return {"error": str(e), "slides": []}
    
    async def expand_content(self, section_title: str, current_content: str) -> str:
        """æ‰©å±•æŒ‡å®šç« èŠ‚çš„å†…å®¹"""
        self.logger.info("ğŸ” å¼€å§‹æ‰©å±•ç« èŠ‚å†…å®¹")
        self.logger.info(f"ğŸ“ ç« èŠ‚æ ‡é¢˜: {section_title}")
        self.logger.debug(f"ğŸ“„ å½“å‰å†…å®¹é•¿åº¦: {len(current_content)} å­—ç¬¦")
        self.logger.debug(f"ğŸ“„ å½“å‰å†…å®¹é¢„è§ˆ: {current_content[:200]}...")
        
        try:
            # æ„å»ºæ‰©å±•æç¤ºè¯
            self.logger.debug("ğŸ”¨ æ„å»ºå†…å®¹æ‰©å±•æç¤ºè¯")
            prompt = f"""
è¯·æ‰©å±•ä»¥ä¸‹ç« èŠ‚çš„å†…å®¹ï¼Œä½¿å…¶æ›´åŠ è¯¦ç»†å’Œä¸°å¯Œï¼š

ç« èŠ‚æ ‡é¢˜ï¼š{section_title}
å½“å‰å†…å®¹ï¼š{current_content}

è¦æ±‚ï¼š
1. ä¿æŒåŸæœ‰å†…å®¹çš„æ ¸å¿ƒè§‚ç‚¹
2. å¢åŠ æ›´å¤šç»†èŠ‚å’Œä¾‹å­
3. ç¡®ä¿å†…å®¹é€»è¾‘æ¸…æ™°
4. å­—æ•°å¢åŠ 50-100%
"""
            self.logger.debug(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            
            # è·å–æ¨¡å‹åç§°
            model_name = self._get_model_name()
            self.logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_name}")
            
            # è°ƒç”¨ AI API æ‰©å±•å†…å®¹
            self.logger.info("âš¡ å¼€å§‹è°ƒç”¨ AI API æ‰©å±•å†…å®¹")
            response = await self.client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹æ‰©å±•å¸ˆï¼Œæ“…é•¿ä¸°å¯Œå’Œå®Œå–„ç°æœ‰å†…å®¹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.6,
                max_tokens=1500
            )
            
            self.logger.success("âœ… å†…å®¹æ‰©å±• API è°ƒç”¨æˆåŠŸ")
            
            # å¤„ç†æ‰©å±•åçš„å†…å®¹
            expanded_content = response.choices[0].message.content
            self.logger.info(f"ğŸ“Š æ‰©å±•åå†…å®¹é•¿åº¦: {len(expanded_content)} å­—ç¬¦")
            self.logger.info(f"ğŸ“ˆ å†…å®¹å¢é•¿: {len(expanded_content) - len(current_content)} å­—ç¬¦")
            self.logger.debug(f"ğŸ“„ æ‰©å±•åå†…å®¹é¢„è§ˆ: {expanded_content[:300]}...")
            
            self.logger.success("ğŸ‰ å†…å®¹æ‰©å±•å®Œæˆ")
            return expanded_content
            
        except Exception as e:
            self.logger.error(f"âŒ æ‰©å±•å†…å®¹å¤±è´¥: {str(e)}")
            self.logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            return f"æ‰©å±•å¤±è´¥: {str(e)}"
    
    def _get_model_name(self) -> str:
        """è·å–æ¨¡å‹åç§°ï¼Œä¼˜å…ˆä½¿ç”¨å·²é…ç½®çš„API"""
        if self.settings.DEEPSEEK_API_KEY:
            return self.settings.DEEPSEEK_MODEL
        elif self.settings.OPENAI_API_KEY:
            return self.settings.OPENAI_MODEL
        elif self.settings.ANTHROPIC_API_KEY:
            return self.settings.ANTHROPIC_MODEL
        else:
            return "deepseek-chat"  # é»˜è®¤æ¨¡å‹
    
    def get_current_provider(self) -> str:
        """è·å–å½“å‰AIæä¾›å•†"""
        if self.settings.DEEPSEEK_API_KEY:
            return "DeepSeek"
        elif self.settings.OPENAI_API_KEY:
            return "OpenAI"
        elif self.settings.ANTHROPIC_API_KEY:
            return "Anthropic"
        else:
            return "æœªé…ç½®"
    
    def _build_outline_prompt(self, request: OutlineGenerateRequest) -> str:
        """æ„å»ºå¤§çº²ç”Ÿæˆæç¤ºè¯"""
        length_map = {
            "ç®€çŸ­": "3-5ä¸ªä¸»è¦ç« èŠ‚",
            "ä¸­ç­‰": "5-8ä¸ªä¸»è¦ç« èŠ‚", 
            "è¯¦ç»†": "8-12ä¸ªä¸»è¦ç« èŠ‚"
        }
        
        sections_requirement = length_map.get(request.outline_length, "5-8ä¸ªä¸»è¦ç« èŠ‚")
        
        prompt = f"""
è¯·ä¸ºä»¥ä¸‹ä¸»é¢˜åˆ›å»ºä¸€ä¸ªè¯¦ç»†çš„PPTæ¼”ç¤ºå¤§çº²ï¼š

ä¸»é¢˜ï¼š{request.topic}
ç›®æ ‡å—ä¼—ï¼š{request.target_audience or 'ä¸€èˆ¬å—ä¼—'}
æ¼”ç¤ºæ—¶é•¿ï¼š{request.presentation_duration or '15-20åˆ†é’Ÿ'}
å¤§çº²è¯¦ç»†ç¨‹åº¦ï¼š{request.outline_length}ï¼ˆ{sections_requirement}ï¼‰
æ¼”ç¤ºè¯­è¨€ï¼š{request.language}

é¢å¤–è¦æ±‚ï¼š
{request.additional_requirements or 'æ— ç‰¹æ®Šè¦æ±‚'}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºå¤§çº²ï¼š

# æ¼”ç¤ºä¸»é¢˜

## 1. å¼€åœºå¼•å…¥
- é—®å€™å’Œè‡ªæˆ‘ä»‹ç»
- ä¸»é¢˜æ¦‚è¿°
- æ¼”ç¤ºå¤§çº²é¢„è§ˆ

## 2. [ä¸»è¦ç« èŠ‚æ ‡é¢˜]
- [ä¸»è¦è§‚ç‚¹1]
  - [æ”¯æ’‘ç»†èŠ‚]
  - [ä¾‹å­æˆ–æ•°æ®]
- [ä¸»è¦è§‚ç‚¹2]
  - [æ”¯æ’‘ç»†èŠ‚]

## 3. [ä¸»è¦ç« èŠ‚æ ‡é¢˜]
...

## ç»“æŸè¯­
- æ€»ç»“è¦ç‚¹
- è¡ŒåŠ¨å‘¼å
- æ„Ÿè°¢å’Œé—®ç­”

è¦æ±‚ï¼š
1. å¤§çº²ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘æ€§å¼º
2. æ¯ä¸ªç« èŠ‚éƒ½æœ‰å…·ä½“çš„å†…å®¹è¦ç‚¹
3. é€‚åˆ{request.presentation_duration or '15-20åˆ†é’Ÿ'}çš„æ¼”ç¤ºæ—¶é•¿
4. å†…å®¹å®ç”¨ä¸”æœ‰ä»·å€¼
5. ä½¿ç”¨{request.language}è¯­è¨€"""

        return prompt
    
    def _build_content_prompt(self, outline: str, template_info: Dict[str, Any]) -> str:
        """æ„å»ºå†…å®¹ç”Ÿæˆæç¤ºè¯"""
        template_name = template_info.get('name', 'é»˜è®¤æ¨¡æ¿')
        template_style = template_info.get('description', 'ç®€æ´ä¸“ä¸šé£æ ¼')
        
        prompt = f"""
åŸºäºä»¥ä¸‹å¤§çº²ï¼Œä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆè¯¦ç»†çš„æ¼”ç¤ºå†…å®¹ï¼š

å¤§çº²ï¼š
{outline}

æ¨¡æ¿ä¿¡æ¯ï¼š
- æ¨¡æ¿åç§°ï¼š{template_name}
- é£æ ¼ç‰¹ç‚¹ï¼š{template_style}

è¯·ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆï¼š
1. æ ‡é¢˜é¡µå†…å®¹
2. è¯¦ç»†å†…å®¹é¡µ
3. å…³é”®è¦ç‚¹æ€»ç»“

è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
  "slides": [
    {{
      "type": "title",
      "title": "ç« èŠ‚æ ‡é¢˜",
      "subtitle": "å‰¯æ ‡é¢˜æˆ–æ¦‚è¿°",
      "section": 1
    }},
    {{
      "type": "content", 
      "title": "å†…å®¹æ ‡é¢˜",
      "content": [
        "è¦ç‚¹1ï¼šè¯¦ç»†è¯´æ˜",
        "è¦ç‚¹2ï¼šè¯¦ç»†è¯´æ˜"
      ],
      "section": 1
    }}
  ]
}}

è¦æ±‚ï¼š
1. å†…å®¹è¯¦å®å…·ä½“ï¼Œé¿å…ç©ºæ³›è¡¨è¿°
2. é€‚åˆæ¼”ç¤ºæ–‡ç¨¿çš„è¡¨è¾¾æ–¹å¼
3. æ¯é¡µå†…å®¹é‡é€‚ä¸­ï¼Œä¾¿äºé˜…è¯»
4. ä¿æŒé£æ ¼ä¸€è‡´æ€§"""

        return prompt
    
    def _parse_outline_to_tree(self, markdown_content: str) -> list:
        """å°† Markdown å¤§çº²è§£æä¸ºæ ‘å½¢ç»“æ„"""
        lines = markdown_content.strip().split('\n')
        tree = []
        current_section = None
        current_subsection = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ä¸»æ ‡é¢˜ (# æˆ– ##)
            if line.startswith('# ') or line.startswith('## '):
                if line.startswith('# '):
                    title = line[2:].strip()
                else:
                    title = line[3:].strip()
                    
                current_section = {
                    "title": title,
                    "level": 1,
                    "children": []
                }
                tree.append(current_section)
                current_subsection = None
                
            # å­æ ‡é¢˜ (### æˆ–æ›´å¤š)
            elif line.startswith('###'):
                if current_section:
                    subtitle = line[3:].strip()
                    current_subsection = {
                        "title": subtitle,
                        "level": 2,
                        "children": []
                    }
                    current_section["children"].append(current_subsection)
                    
            # åˆ—è¡¨é¡¹
            elif line.startswith('- '):
                content = line[2:].strip()
                item = {
                    "title": content,
                    "level": 3,
                    "children": []
                }
                
                if current_subsection:
                    current_subsection["children"].append(item)
                elif current_section:
                    current_section["children"].append(item)
        
        return tree
    
    def _parse_content_to_slides(self, content: str) -> Dict[str, Any]:
        """è§£æç”Ÿæˆçš„å†…å®¹ä¸ºå¹»ç¯ç‰‡æ ¼å¼"""
        try:
            # å°è¯•è§£æ JSON æ ¼å¼çš„å†…å®¹
            return json.loads(content)
        except json.JSONDecodeError:
            # å¦‚æœä¸æ˜¯ JSON æ ¼å¼ï¼Œåˆ™è¿›è¡Œç®€å•çš„æ–‡æœ¬è§£æ
            lines = content.strip().split('\n')
            slides = []
            current_slide = None
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                if line.startswith('#'):
                    if current_slide:
                        slides.append(current_slide)
                    
                    title = line.lstrip('#').strip()
                    current_slide = {
                        "type": "content",
                        "title": title,
                        "content": [],
                        "section": len(slides) + 1
                    }
                elif line.startswith('-') and current_slide:
                    current_slide["content"].append(line[1:].strip())
            
            if current_slide:
                slides.append(current_slide)
            
            return {"slides": slides} 